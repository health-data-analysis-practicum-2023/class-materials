---
title: "Class 1-7: Discussion of propensity score results"
author: "Health Data Analysis Practicum (AS.280.347)"
date: "February 13, 2023"
output: 
  html_document:
    toc: true
    toc_float: 
      toc_collapsed: true
    toc_depth: 3
    number_sections: false
---

**Note:** Valentine's hearts courtesty of Emily Riederer (https://github.com/emilyriederer/demo-rmd-snow) To turn them off, you can delete the chunk of code below from lines 16 through 47.



```{css echo = FALSE}
/*Source: https://codepen.io/codeconvey/pen/xRzQay*/
  
/* customizable snowflake styling */
.snowflake {
  color: #F55491;
  font-size: 5em;
  font-family: Arial;
  text-shadow: 0 0 1px #000;
}
@-webkit-keyframes snowflakes-fall{0%{top:-10%}100%{top:100%}}
@-webkit-keyframes snowflakes-shake{
    0%{-webkit-transform:translateX(0px);transform:translateX(0px)}
   50%{-webkit-transform:translateX(80px);transform:translateX(80px)}
  100%{-webkit-transform:translateX(0px);transform:translateX(0px)}}
@keyframes snowflakes-fall{
    0%{top:-10%}
  100%{top:100%}}
@keyframes snowflakes-shake{
    0%{transform:translateX(0px)}
   50%{transform:translateX(80px)}
  100%{transform:translateX(0px)}}
.snowflake{
  position:fixed;
  top:-10%;
  z-index:9999;
  -webkit-user-select:none;
  -moz-user-select:none;
  -ms-user-select:none;
  user-select:none;
  cursor:default;
  -webkit-animation-name:snowflakes-fall,snowflakes-shake;
  -webkit-animation-duration:10s,3s;
  -webkit-animation-timing-function:linear,ease-in-out;
  -webkit-animation-iteration-count:infinite,infinite;
  -webkit-animation-play-state:running,running;
  animation-name:snowflakes-fall,snowflakes-shake;
  animation-duration:10s,3s;
  animation-timing-function:linear,ease-in-out;
  animation-iteration-count:infinite,infinite;
  animation-play-state:running,running}
.snowflake:nth-of-type(0){left: 1%;-webkit-animation-delay:  0s,  0s;animation-delay:  0s,  0s}
.snowflake:nth-of-type(1){left:10%;-webkit-animation-delay:  1s,  1s;animation-delay:  1s,  1s}
.snowflake:nth-of-type(2){left:20%;-webkit-animation-delay:  6s,0.5s;animation-delay:  6s,0.5s}
.snowflake:nth-of-type(3){left:30%;-webkit-animation-delay:  4s,  2s;animation-delay:  4s,  2s}
.snowflake:nth-of-type(4){left:40%;-webkit-animation-delay:  2s,  2s;animation-delay:  2s,  2s}
.snowflake:nth-of-type(5){left:50%;-webkit-animation-delay:  8s,  3s;animation-delay:  8s,  3s}
.snowflake:nth-of-type(6){left:60%;-webkit-animation-delay:  6s,  2s;animation-delay:  6s,  2s}
.snowflake:nth-of-type(7){left:70%;-webkit-animation-delay:2.5s,  1s;animation-delay:2.5s,  1s}
.snowflake:nth-of-type(8){left:80%;-webkit-animation-delay:  1s,  0s;animation-delay:  1s,  0s}
.snowflake:nth-of-type(9){left:90%;-webkit-animation-delay:  3s,1.5s;animation-delay:  3s,1.5s}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = TRUE)
knitr::opts_knit$set(root.dir = "/cloud/project")
```

## Preliminaries

First load the packages that we will be using in this document:
```{r}
library(tidyverse)  # core group of tidyverse packages
library(kableExtra)  # to make nice tables
library(broom)  # for tidy model summaries
```

## Module 1: Smoking and the risk of disease

Questions of interest:

* **Question 1.1: ** How does the risk of disease compare for smokers and otherwise similar non-smokers?

<center>
![](Q1_dag.png){width=500px}
</center>

* **Queston 1.2: ** Does the contribution of smoking to the risk of disease vary by sex or socio-economic status (SES)?

<center>
![](Q2_dag.png){width=500px}
</center>

To address each question we want:

* A data display (graph or table)
* A statistical analysis (with interprepration)

We will answer these questions using data from the National Medical Expenditures Survey (NMES)

## Discussion of propensity scores verses logistic regression for Question 1-1

In your small groups, take 20 minutes to discuss the results of your propensity score analysis and multivariable logistic regression to answer Question 1.1.  Feel free to refer to the [Piazza thread](https://piazza.com/class/ld7tidrzlpp70o/post/17){target="_blank"} with all student results, but below you can find pasted some of the student comments comparing the two analysis methods: 

* Both of these analysis methods can sufficiently answer Question 1.1. If I had to make an educated guess on which of the two methods is preferred for answering Question 1.1, I would say that conducting logistic regression with propensity scores is preferred. In this method, you can produce quintiles with a similar propensity score with respect to many confounders with in a way that is relatively easy to interpret and conceptualize.  However, with multivariable logistic regression, many different strata are required when you incorporate more and more variables you incorporate into your model. Having so many strata can become difficult to manage.

* The propensity score analysis is probably preferred for answering Question 1.1 since there are multiple confounding variables to account for. This method allows for a more organized estimation with fewer stratifications that is easier to interpret than the multivariable logistic regression model.

* I think the propensity score analysis method is preferred for answering Question 1.1 because you can control for multiple potential confounders without worrying about comparison groups being too small unlike for the multivariable logistic regression method. 

* Because my analysis for the propensity score did not compute anything statistically significant, I would say the multivariable logistic regression model is preferred for answering Question 1.1.

* The eversmoking coefficient with the multivariable logistic regression (2.189) was greater than the coefficient produced with the propensity score analysis (1.544). Therefore, the odds ratio comparing eversmokers to otherwise similar (in terms of sex, age, and poverty status) neversmokers was greater than the odds ratio in the propensity score analysis. Thus, in terms of the research question, the risk of disease in eversmokers compared to neversmokers is greater when using multivariable logistic regression than with propensity score analysis. I prefer propensity score analysis as this allows us to control for many confounding variables without worrying about excessive stratification or small comparison groups (especially when concerning a continuous variable such as age).

* A propensity score analysis is more likely preferred over our previous logistic regression given its standardization methods using quintiles, allowing for a more systematic accounting of possible confounding variables.

* To answer question 1-1, I prefer the flexibility that the propensity score offers to consolidate many potential confounding variables into one score, and then model by quintile. 

* On the matter of preference, I believe that applying logistic regression with propensity scores is preferred in terms of helping to reduce potential confounding/bias by equating groups based on covariates rather than stratification which could result in very small comparison groups.

* In regards to which analysis method is best to answer Question 1.1, the multivariate regression considering the propensity scores is preferred. While both methods yield similar OR, the regression using propensity scores has a smaller confidence interval. Also, using propensity scores allows for easier interpretation when needed to account for many confounding variables.

* Both the logistic regression and propensity score methods have their benefits. The multivariable logistic regression gave useful output regarding specific variables of interest - which allows us to assess which variables are most impactful in the model. The propensity score method offers a more technical approach to matching similar participants. I prefer the propensity score method to address question 1.1 because it does the best job of comparing otherwise similar participants on a single variable - in this case smoker status.

* Both can answer the main question.  I think using propensity scores is better because categories account for multiple confounders at once.

* I prefer the first model because propensity scores feel less intuitive to me. I hope to become more comfortable to make full use of this analysis method.

Discuss the following questions:

(1) How do the multivariable logistic regression results change depending on which adjustment variables are included in the model?  Do you think this is a problem?  Do these differences change the answer to Question 1.1?

(2) How do the results from the propensity score analyses compare to those from logistic regression?  Do you think any differences in the results are a problem?  Do these differences change the answer to Question 1.1?

(3) What are some of the pros/cons for each analysis method (logistic regression vs. propensity analysis)?  In particular, look at the width of the confidence intervals for the estimated odds ratios comparing smokers to non-smokers for the multi-variate logistic regression vs the propensity score models. Which method do you prefer in this case, and why?

(4) In the student results, was it always clear which variables were included as adjustment variables in the logistic regression model?  Was is always clear which variables were included as adjustment variables in the propensity analysis?  If not, what are suggestions for either the table of results or the write-up that could make this clear?

(5) Were they any interpretations of results (for either model) that you found particularly well done?  What were the characteristics of those interpretations?

(6) What are your lingering questions about propensity scores?

## R notes based Assignment 1-3

Just a few notes this week: including numbers from your regression results directly into the text in R Markdown writing numerate sentences when summarizing your results.  Reminder: you should also feel free to ask questions on Piazza if there is something you would like us to help you learn how to do!

### Recoding the data
```{r}
nmes_data <- read_csv("module_1/nmesUNPROC.csv")

nmes_data <- nmes_data %>%
  mutate(eversmk = factor(eversmk, levels = c("0", "1"), labels = c("Never smoker", "Ever smoker")),
         lc5 = factor(lc5, levels = c("0", "1"), labels = c("No LC", "LC")),
         chd5 = factor(chd5, levels = c("0", "1"), labels = c("No CHD", "CHD")),
         female = factor(female, levels= c("0", "1"), labels = c("Male", "Female")),
         current = factor(current, levels= c("0", "1"), labels = c("Not current smoker", "Current smoker")),
         former = factor(former, levels= c("0", "1"), labels = c("Not former smoker", "Former smoker")),
         beltuse = factor(beltuse, levels= c("1", "2", "3"), labels = c("Rare", "Some", "Almost always")),
         educate = factor(educate, levels= c("1", "2", "3", "4"), labels = c("College grad", "Some college", "HS grad", "Other")),
         marital = factor(marital, levels= c("1", "2", "3", "4", "5"), labels = c("Married", "Widowed", "Divorced", "Separated", "Never married")),
         poor = factor(poor, levels= c("0", "1"), labels = c("Not poor", "Poor"))
         )

nmes_data <- nmes_data %>%
  mutate(disease = factor(lc5 == "LC" | chd5 == "CHD", 
                          levels=c(FALSE,TRUE), 
                          labels=c("No MSCD", "MSCD")))
```

### Propensity scores with smaller groups

Why does it not really make a difference if you use logistic regression or propensity score groups when you have only two binary variables?

First, we use logistic regression to model the log odds of ever smoking based on female and poor:
```{r}
prop_model <- glm(eversmk ~ female + poor, family = binomial(link="logit"), data=nmes_data, na.action = na.exclude)

nmes_data <- nmes_data %>%
  mutate(ps = predict(prop_model, type = "response"))


ggplot(data = nmes_data) +
  geom_jitter(mapping = aes(x=ps, y=disease, color=eversmk), alpha = .4) 
```

Note that propensity score groups are completely determined by the female and poor variables:
```{r}
ggplot(data = nmes_data) +
  geom_jitter(mapping = aes(x=ps, y=disease, color=female, shape = poor), alpha = .4) 

```

If we want to have at least four propensity score groups, this means that we would be splitting people into the exact groups they would be split into by the sex/poverty status variables, not providing any benefit. 


### In-line code (including code in within the text)

In your written interpretations of your regression results, you all refer to values that are also presented in your tables of coefficients or odds ratios.  Instead of copying/pasting or typing these numbers into the text, you can refer directly to the values in your tables within your text.  This is called "in-line" code, and it is done using: tick r.

For example, suppose we created the following table of logistic regression results:
```{r}
my_model <- glm(disease ~ eversmk + age + female, family=binomial(link="logit"), data=nmes_data)

my_model_results <- tidy(my_model, 
                         exponentiate = TRUE,
                         conf.int = TRUE)

my_model_results$term <- c("Intercept", "Ever smoker", "Age (years)", "Female")

my_model_results
```

And we displayed it nicely in the following table:
```{r}
my_model_results %>%
  filter(term != "Intercept") %>% # remove the row with the intercept
  mutate(conf.int = paste0("(", round(conf.low, 2), ", ", round(conf.high, 2), ")")) %>% # combine the CI terms together into nice format 
  select(Variable = term, `Odds Ratio` = estimate, `p-value` = p.value, `95% Confidence Interval` = conf.int) %>% # select only the columns we want, rearrange columns, and change names
  kable(format = "pipe",
        digits = 3,
        align = c("l", "r", "r", "r"))
```

In the text, we might interpret the results as:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is 2.2 times the odds of having a disease for non-smokers.

**If we don't want to type out this number, we could use in-line R code instead:** In our table of results (`my_model_results`), the odds ratio for smoking is stored in the `estimate` column where `term == "Ever smoker"`.  We can access that specific table location with:
```{r}
my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull()
```

Here the `pull()` function is used to give a single value rather than return a table.  We can then put this value within our text as `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull()`.  When the report is knit, the results of this code are inserted into the text.

When inserting numbers into text, `format()` is your friend. It allows you to set the number of digits so you donâ€™t print to a ridiculous degree of accuracy.  We can also add `big.mark = ","` to make numbers easier to read or specify that we do not want to use scientific notation here:
```{r}
format(3452345, digits = 2, big.mark = ",")
format(0.12358124331, digits = 2, big.mark = ",")
format(9e-2, digits = 3, scientific = FALSE)
```

So we could re-write our results as:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers.

### Stating numerate results

When writing up your results, be sure to be numerate!  This means including actual values of odds ratios in your write-up (see above), but also means to include information about the statistical significance as well, with supporting evidence like a confidence interval of p-value.  For example, we could improve our intepretation above in a couple of ways:

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers (p = `r my_model_results %>% filter(term == "Ever smoker") %>% select(p.value) %>% pull() %>% format(digits = 2, scientific = FALSE)`).

OR

Holding age and sex constant, the odds of having a major smoking-caused disease among smokers is `r my_model_results %>% filter(term == "Ever smoker") %>% select(estimate) %>% pull() %>% format(digits = 2)` times the odds of having a disease for non-smokers (95% CI for odds ratio: `r my_model_results %>% filter(term == "Ever smoker") %>% select(conf.low) %>% pull() %>% format(digits = 2)` to `r my_model_results %>% filter(term == "Ever smoker") %>% select(conf.high) %>% pull() %>% format(digits = 2)`).


### Adding figure captions and other graph tips

We can add figure captions to our plots in R Markdown.  This code chunk creates a string that will be used below as a figure caption:
```{r}
figcap.nmes = paste0("Figure 1: Scatter plot of log10 medical expenditures vs age for n=", nrow(nmes_data), " observations")
```

We can then add this figure caption to our code chunk header using the `fig.cap` argument in the code chunk header:
```{r, fig.cap = figcap.nmes}
nmes_data %>%
  mutate(log10exp = log10(totalexp)) %>%
  ggplot(mapping = aes(x = age, y = log10exp)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = "red")
``` 

Note that we can use options like `include = FALSE`, `echo = FALSE`, and `message = FALSE` in our code chunk headers to control what is printed out in the actual report.  So if we just want to include the graph and not the code for either the graph or the caption we could set `include = FALSE` for the caption definition chunk and `echo = FALSE` for the plot chunk.  We can also supress the message about `geom_smooth` by including `message = FALSE` in our chunk for the graph.

Then we **just** get the graph in our report while hiding all the code that went into creating it!

```{r include = FALSE}
figcap.nmes = paste0("Figure 1: Scatter plot of log10 medical expenditures vs age for n=", nrow(nmes_data), " observations")
```

```{r, fig.cap = figcap.nmes, echo = FALSE, message = FALSE}
nmes_data %>%
  mutate(log10exp = log10(totalexp)) %>%
  ggplot(mapping = aes(x = age, y = log10exp)) + 
  geom_point() + 
  geom_smooth(se = FALSE, color = "red")
``` 

## Interpreting propensity score results

Suppose we calculate propensity scores based on **age** and **sex**:
```{r}
# fit propensity score model: trt ~ confounders
prop_model <- glm(eversmk ~ age + female, family = binomial(link="logit"), data=nmes_data, na.action = na.exclude)

# calculate propensity scores:
nmes_data <- nmes_data %>%
  mutate(ps = predict(prop_model, type = "response"))

# calculate propensity score quintiles:
ps_quintiles <- quantile(nmes_data$ps, probs=c(0, 0.2, 0.4, 0.6, 0.8, 1), na.rm=TRUE)

nmes_data <- nmes_data %>%
  mutate(ps_strata = cut(ps, breaks=ps_quintiles, include.lowest=TRUE))

# model log odds of disease from smoking and ps quintiles
model_ps_strata <- glm(disease ~ eversmk + ps_strata, family = binomial(link="logit"), data=nmes_data)
summary(model_ps_strata)

# transform log OR to OR
exp(coef(model_ps_strata))
```

We would interpret the coefficient for `eversmk` as follows.  We *do not* need to interpret the coefficients for the propensity score quintiles because these variables are just there for adjustment purposes are are not the relationship of interest!

<center>
![](PS_interpretation.png){width=600px}
</center>

## Looking ahead to Wednesday: Effect modification

On Wednesday we will finally consider **Queston 1.2: ** Does the contribution of smoking to the risk of disease vary by sex or socio-economic status (SES)?

<center>
![](Q2_dag.png){width=500px}

</center>

An **effect modification** (or **interaction**) is present when the relationship between a predictor of interest and the outcome varies by the level (subgroup) of another variable.

For example, if we thought the effect of smoking on disease was different (larger or smaller) for males than it is for females, we would want to consider a model that allows sex to *modify* the relationship between smoking and disease.

### Discussion: How can we investigate whether sex *modifies* the relationship between smoking and disease using a data display?

Let's start with a display similar to what we've already considered for Question 1.1:

```{r}
my_table <- nmes_data %>%
  count(female, eversmk, disease) %>%
  group_by(female, eversmk) %>%
  mutate(prop = n/sum(n)) %>%
  filter(disease == "MSCD")

my_table %>%
  ggplot() +
  geom_bar(aes(x = eversmk, y = prop), stat = "identity") + 
  facet_wrap(~ female)
```

What, if anything, does this graph suggest about whether there's a different relationship between smoking and disease for male compared to female individuals?


## Assignment 1.4: Final Module 1 Report

Finalize your report for Module 1 to answer Questions 1.1 and 1.2.

* For each question, you should have a data display and a statistical analysis to address the question.
* For Question 1.1, decide whether you want to use a multivariable logistic regression model or a propensity score analysis to answer the question.
* For Question 1.2, choose *either* sex or a variable related to SES and create a graph to investigate whether there is effect modification present.
* For Question 1.2, choose *either* sex or a variable related to SES and include an interaction in either your multivariable logistic regression or your propensity score analysis to formally test whether effect modification exists. 


You should also do the following:

* Provide a caption for your data displays.
* Write up your results in a few paragraphs to answer both questions.  In your write-up, you should refer to your data displays and your analysis results.  Be numerate!
* Here's a great resource for tables/figures for scientific papers:
[http://abacus.bates.edu/~ganderso/biology/resources/writing/HTWtablefigs.html](http://abacus.bates.edu/~ganderso/biology/resources/writing/HTWtablefigs.html)

Submit your data display in R Markdown through Github by Monday (February 20, 2023) at midnight.

* You may work together on this assignment, but you must submit your own assignment; please credit in your assignment anyone with whom you collaborated.

* Next week in class we will start Module 2!